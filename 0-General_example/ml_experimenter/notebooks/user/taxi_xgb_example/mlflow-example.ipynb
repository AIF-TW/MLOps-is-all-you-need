{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef39105c-fa68-4275-8f9c-c9dc80a0858b",
   "metadata": {},
   "source": [
    "# Environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe7d75f-1152-4c61-9031-101842d9cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23932b49-5ef5-4921-bcc9-348831b3fb0e",
   "metadata": {},
   "source": [
    "# MLFLOW Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462891e2-1232-467b-a741-9a25c5cefdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a610cfdc-6139-49ea-86c3-84515e4540b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_experiment(EXPERMENT_NAME = \"nyc-taxi-experiment\"):\n",
    "    # setting experiment name \n",
    "    existing_exp = mlflow.get_experiment_by_name(EXPERMENT_NAME)\n",
    "    if not existing_exp:\n",
    "        mlflow.create_experiment(EXPERMENT_NAME, \"s3://\"+os.getenv('MLFLOW_BUCKET_NAME')+\"/\")\n",
    "    mlflow.set_experiment(EXPERMENT_NAME)\n",
    "    \n",
    "def preprocessor(df):\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df.loc[:,'duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.loc[:,'duration'] = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    df.loc[:,'PU_DO'] = df['PULocationID'].astype(str) + '_' + df['DOLocationID'].astype(str)\n",
    "    \n",
    "    target = 'duration'\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "\n",
    "    x = df[categorical + numerical]\n",
    "    y = df[target].values\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train_model_search(train, valid, y_val):\n",
    "    def objective(params):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag(\"model\", \"xgboost\")\n",
    "            mlflow.log_params(params)\n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=train,\n",
    "                # num_boost_round=100,\n",
    "                num_boost_round=2,\n",
    "                evals=[(valid, 'validation')],\n",
    "                # early_stopping_rounds=20\n",
    "            )\n",
    "            y_pred = booster.predict(valid)\n",
    "            rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "        'objective': 'reg:linear',\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=1,\n",
    "        trials=Trials()\n",
    "    )\n",
    "\n",
    "    return best_result\n",
    "\n",
    "\n",
    "def train_best_model(train, valid, y_val, \n",
    "                     dv, best_result, X_train): # for log_model\n",
    "    with mlflow.start_run() as run:\n",
    "        # parameters \n",
    "        best_params = {\n",
    "            'learning_rate': best_result['learning_rate'],\n",
    "            'max_depth': int(best_result['max_depth']),\n",
    "            'min_child_weight': best_result['min_child_weight'],\n",
    "            'objective': 'reg:linear',\n",
    "            'reg_alpha': best_result['reg_alpha'],\n",
    "            'reg_lambda': best_result['reg_lambda'],\n",
    "            'seed': 42\n",
    "        }\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # model\n",
    "        booster = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=train,\n",
    "            # num_boost_round=100,\n",
    "            num_boost_round=2,\n",
    "            evals=[(valid, 'validation')],\n",
    "            # early_stopping_rounds=50\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # artifacts\n",
    "        artifacts = { # this dict will server to XGBmodel as 'context.artifacts'\n",
    "            'preprocessor': 'preprocessor.b',\n",
    "            'dv': 'dv.b',\n",
    "            'model':'xgb.json'\n",
    "        }\n",
    "\n",
    "        with open(\"preprocessor.b\", \"wb+\") as f_out:\n",
    "            dill.dump(preprocessor, f_out)\n",
    "        with open('dv.b', 'wb+') as f_out:\n",
    "            dill.dump(dv, f_out)\n",
    "        booster.save_model('xgb.json')\n",
    "        \n",
    "        # signature\n",
    "        signature = infer_signature(X_train, y_pred) # sample of input, output # not support pandas.dtyp.object\n",
    "        pip_requirements = [\"-r requirements.txt\"]\n",
    "        \n",
    "        # customized model class \n",
    "        class XGBmodel(mlflow.pyfunc.PythonModel):\n",
    "            def load_context(self, context): # called when load_model\n",
    "                import dill\n",
    "                import xgboost as xgb\n",
    "                import pandas as pd\n",
    "\n",
    "                with open(context.artifacts[\"preprocessor\"], \"rb\") as f:\n",
    "                    self.preprocessor = dill.load(f)\n",
    "                with open(context.artifacts[\"dv\"], \"rb\") as f:\n",
    "                    self.dv = dill.load(f)\n",
    "                    \n",
    "                self.model = xgb.Booster()\n",
    "                self.model.load_model(context.artifacts[\"model\"])\n",
    "\n",
    "            def predict(self, context, model_input): # called when model.predict \n",
    "                # suppose input type is pd.dataframe\n",
    "                X_test = model_input.to_dict(orient='records')\n",
    "                X_test = self.dv.transform(X_test)\n",
    "                X_test = xgb.DMatrix(X_test)\n",
    "                return self.model.predict(X_test)\n",
    "\n",
    "        # logModel\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model=XGBmodel(),\n",
    "            artifacts=artifacts,\n",
    "            signature=signature,\n",
    "            pip_requirements=pip_requirements\n",
    "        )\n",
    "\n",
    "def main(train_path: str=\"./data/green_tripdata_2021-01.parquet\",\n",
    "        val_path: str=\"./data/green_tripdata_2021-02.parquet\",\n",
    "        EXPERMENT_NAME = \"nyc-taxi-experiment\"):\n",
    "    \n",
    "    set_experiment(EXPERMENT_NAME)\n",
    "\n",
    "    # prepare data\n",
    "    df_train = pd.read_parquet(train_path)\n",
    "    df_val = pd.read_parquet(val_path)\n",
    "\n",
    "    X_train, y_train = preprocessor(df_train)\n",
    "    X_val, y_val = preprocessor(df_val)\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    X_train_trans = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "    X_val_trans = dv.transform(X_val.to_dict(orient='records'))\n",
    "\n",
    "    train = xgb.DMatrix(X_train_trans, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val_trans, label=y_val)\n",
    "\n",
    "    best_result = train_model_search(train, valid, y_val)\n",
    "    train_best_model(train, valid, y_val, dv, best_result, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d599bd-ec1a-4b1c-bf49-674bfc481a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134/1725771317.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:,'PU_DO'] = df['PULocationID'].astype(str) + '_' + df['DOLocationID'].astype(str)\n",
      "/tmp/ipykernel_134/1725771317.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:,'PU_DO'] = df['PULocationID'].astype(str) + '_' + df['DOLocationID'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:54:46] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:18.33514                         \n",
      "[1]\tvalidation-rmse:15.98775                         \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/trial, best loss: 15.987749428981637]\n",
      "[04:54:46] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:18.33514\n",
      "[1]\tvalidation-rmse:15.98775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6fbe9-5780-45f7-b767-be7e894b2fe8",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0297801e-c66c-4607-9b9e-4bc2d35a1a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last run id = 2123ab759b49426b82efa2d6b1475e96\n"
     ]
    }
   ],
   "source": [
    "run_id = mlflow.last_active_run().info.run_id\n",
    "print('last run id =', run_id)\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5cb197-4315-428a-bda0-868d75661db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5980784, 4.32699  ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'PU_DO':['43_151', '166_239'], \n",
    "    'trip_distance':[1.01, 2.53]\n",
    "}\n",
    "\n",
    "X = pd.DataFrame(data)\n",
    "loaded_model.predict(X)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0168c93-3042-429e-8183-7e10415fcac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
